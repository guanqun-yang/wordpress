---
title: Talk Notes | Data-Centric NLP @ USC CSCI-699 Fall 2022
tags: 
- Data-Centric AI
categories:
- Talk
---


# Outline

The following is the course schedule (indeed a course schedule) compiled from the [course website](https://swabhs.com/csci699-dcnlp/details/detailed_calendar/) for quick reference.

| Section | Date   | Topic                                                 | Readings                                                     |
| ------ | ----------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| I. Datasets in NLP | Aug 22         | Introduction, Historical Perspective, and Overview | [Fair ML Book](https://fairmlbook.org/datasets.html) Chapter 7. Datasets<br/>[Sambasivan et al., 2021](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/0d556e45afc54afeb2eb6b51a9bc1827b9961ff4.pdf): "Everyone wants to do the model work, not the data work": Data Cascades in High-Stakes AI<br />[Paullada et al., 2021](https://arxiv.org/abs/2012.05345) Data and its (dis)contents<br/>[Raji et al., 2022](https://icml.cc/virtual/2022/workshop/13477) Ethical Challenges of Data Collection & Use in Machine Learning Research |
|  | Aug 24 | Data Collection and Data Ethics | [Deng et al., 2009](https://ieeexplore.ieee.org/document/5206848) ImageNet: A large-scale hierarchical image database<br/>[Kwiatkowski et al., 2019](https://aclanthology.org/Q19-1026) Natural Questions: A Benchmark for Question Answering Research<br/>[Sakaguchi et al., 2019](https://arxiv.org/abs/1907.10641) WinoGrande: An Adversarial Winograd Schema Challenge at Scale<br />[Bowman et al. 2015](https://aclanthology.org/D15-1075/) A large annotated corpus for learning natural language inference<br/>[Nie et al., 2020](https://arxiv.org/abs/1910.14599) Adversarial NLI: A New Benchmark for Natural Language Understanding |
|  | Aug 31 | More on Data Ethics | [Bender et al., 2021](https://dl.acm.org/doi/10.1145/3442188.3445922) On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?<br/>[Koch et al., 2021](https://arxiv.org/abs/2112.01716) Reduced, Reused and Recycled: The Life of a Dataset in Machine Learning Research<br />[Klein and D’Ignazio, 2020](https://data-feminism.mitpress.mit.edu/pub/frfa9szd/release/6) Data Feminism Book: [Intro](https://data-feminism.mitpress.mit.edu/pub/frfa9szd/release/6) and [Chapter 1](https://data-feminism.mitpress.mit.edu/pub/vi8obxh7/release/4?readingCollection=0cd867ef)<br/>[Strubell et al., 2019](https://arxiv.org/abs/1906.02243) Energy and Policy Considerations for Deep Learning in NLP |
| II. Bias and Mitigation | Sep 7 | Biases: An Overview | [Geirhos et al., 2020](https://arxiv.org/abs/2004.07780) Shortcut Learning in Deep Neural Networks<br/>[Hort et al., 2022](https://arxiv.org/abs/2207.07068) Bias Mitigation for Machine Learning Classifiers: A Comprehensive Survey<br/>[Feder et al., 2021](https://arxiv.org/abs/2109.00725) Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond |
|  | Sep 12 | Spurious Biases I | [Torralba & Efros, 2011](https://ieeexplore.ieee.org/document/5995347) Unbiased Look at Dataset Bias<br/>[Geva et al., 2019](https://arxiv.org/abs/1908.07898) Are We Modeling the Task or the Annotator? An Investigation of Annotator Bias in Natural Language Understanding Datasets<br/>[McCoy et al., 2019](https://aclanthology.org/P19-1334) Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in NLI |
|  | Sep 14 | Spurious Biases II | [Gardner et al., 2021](https://arxiv.org/abs/2104.08646) Competency Problems: On Finding and Removing Artifacts in Language Data<br/>[Eisenstein, 2022](https://arxiv.org/abs/2204.04487) Informativeness and Invariance: Two Perspectives on Spurious Correlations in Natural Language |
|  | Sep 19 | Data-Centric Bias Mitigation | [Srivastava et al., 2020](https://arxiv.org/abs/2007.06661) Robustness to spurious correlations via human annotations<br/>[Dixon et al., 2018](https://dl.acm.org/doi/abs/10.1145/3278721.3278729) Measuring and mitigating unintended bias in text classification<br/>[Gardner et al., 2019](https://aclanthology.org/D19-5815) On Making Reading Comprehension More Comprehensive |
|  | Sep 21 | Data Augmentation for Bias Mitigation | [Ng et al., 2020](https://aclanthology.org/2020.emnlp-main.97) SSMBA: Self-Supervised Manifold Based Data Augmentation for Improving O.O.D. Robustness<br/>[Kaushik et al., 2019](https://arxiv.org/abs/1909.12434) Learning the Difference that Makes a Difference with Counterfactually-Augmented Data |
| III. Estimating Data Quality | Sep 26 | Estimates of Data Quality | [Le Bras et al., 2020](https://arxiv.org/abs/2002.04108) Adversarial Filters of Dataset Biases<br/>[Swayamdipta et al., 2020](https://arxiv.org/abs/2009.10795) Dataset Cartography: Mapping and Diagnosing Datasets with Training Dynamics<br/>[Liu et al., 2022](https://arxiv.org/abs/2201.05955) WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation<br/>[Ethayarajh et al., 2022](https://arxiv.org/abs/2110.08420) Understanding Dataset Difficulty with V-Usable Information |
|  | Sep 28 | Aggregate vs. Point-wise Estimates of Data Quality    | [Ghorbani & Zou, 2019](https://arxiv.org/abs/1904.02868) Data Shapley: Equitable Valuation of Data for Machine Learning;<br />[Perez et al., 2021](https://arxiv.org/abs/2103.03872) Rissanen Data Analysis: Examining Dataset Characteristics via Description Length;<br />[Mindermann et al., 2022](https://arxiv.org/abs/2206.07137) Prioritized Training on Points that are Learnable, Worth Learning, and Not Yet Learnt |
|   | Oct 3  | Anomalies, Outliers, and Out-of-Distribution Examples | [Hendrycks et al., 2018](https://arxiv.org/abs/1812.04606) Deep Anomaly Detection with Outlier Exposure<br />[Ren et al., 2019](https://proceedings.neurips.cc/paper/2019/file/1e79596878b2320cac26dd792a6c51c9-Paper.pdf) Likelihood Ratios for Out-of-Distribution Detection |
|   | Oct 5  | Disagreements, Subjectivity and Ambiguity I           | [Pavlick et al., 2019](https://aclanthology.org/Q19-1043/) Inherent Disagreements in Human Textual Inferences; <br />[Röttger et al., 2022](https://arxiv.org/abs/2112.07475) Two Contrasting Data Annotation Paradigms for Subjective NLP Tasks; <br />[Denton et al., 2021](https://arxiv.org/abs/2112.04554) Whose Ground Truth? Accounting for Individual and Collective Identities Underlying Dataset Annotation |
|  | Oct 12 | Disagreements, Subjectivity and Ambiguity II          | [Miceli et al., 2020](https://arxiv.org/abs/2007.14886) Between Subjectivity and Imposition: Power Dynamics in Data Annotation for Computer Vision;<br />[Davani et al., 2021](https://arxiv.org/abs/2110.05719) Dealing with Disagreements: Looking Beyond the Majority Vote in Subjective Annotations |
| IV. Data for Accountability | Oct 17 | Creating Evaluation Sets                              | [Recht et al., 2019](https://arxiv.org/abs/1902.10811) Do ImageNet Classifiers Generalize to ImageNet?;<br />[Card et al., 2020](https://arxiv.org/abs/2010.06595) With Little Power Comes Great Responsibility;<br />[Clark et al. 2021](https://aclanthology.org/2021.acl-long.565/) All That’s ‘Human’ Is Not Gold: Evaluating Human Evaluation of Generated Text<br />[Ethayarajh & Jurafsky, 2020](https://arxiv.org/abs/2009.13888) Utility is in the eye of the user: a critique of NLP leaderboards |
|  | Oct 19 | Counterfactual Evaluation                             | [Gardner et al., 2020](https://arxiv.org/abs/2004.02709) Evaluating Models’ Local Decision Boundaries via Contrast Sets;<br />[Ross et al., 2021](https://arxiv.org/abs/2107.07150) Tailor: Generating and Perturbing Text with Semantic Controls |
|  | Oct 24 | Adversarial Evaluation                                | [Jia and Liang, 2017](https://arxiv.org/abs/1707.07328) Adversarial Examples for Evaluating Reading Comprehension Systems;<br />[Kiela et al., 2021](https://arxiv.org/abs/2104.14337) Dynabench: Rethinking Benchmarking in NLP;<br />[Li and Michael, 2022](https://aclanthology.org/2022.dadc-1.4/) Overconfidence in the Face of Ambiguity with Adversarial Data |
|  | Oct 26 | Contextualizing Decisions                             | [Gebru et al., 2018](https://arxiv.org/abs/1803.09010) Datasheets for Datasets;<br />[Bender and Friedman, 2018](https://aclanthology.org/Q18-1041/) Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science |
| V. Beyond Labeled Datasets | Oct 31     | Unlabeled Data                         | [Dodge et al., 2021](https://arxiv.org/abs/2104.08758) Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus<br>[Lee et al., 2022](https://arxiv.org/abs/2107.06499) Deduplicating Training Data Makes Language Models Better<br>[Gururangan et al., 2022](https://arxiv.org/abs/2201.10474) Whose Language Counts as High Quality? Measuring Language Ideologies in Text Data Selection |
|       | Nov 2      | Prompts as Data?                      | [Wei et al., 2022](https://arxiv.org/abs/2201.11903) Chain of Thought Prompting Elicits Reasoning in Large Language Models                                   |
|       | Nov 7      | Data Privacy and Security              | [Amodei et al., 2016](https://arxiv.org/abs/1606.06565) Concrete Problems in AI Safety<br>[Carlini et al., 2020](https://arxiv.org/abs/2012.07805) Extracting Training Data from Large Language Models<br>[Henderson et al., 2022](https://arxiv.org/abs/2207.00220) Pile of Law: Learning Responsible Data Filtering from the Law and a 256GB Open-Source Legal Dataset |
|       | Nov 9      | Towards Better Data Citizenship         | [Jo & Gebru, 2019](https://arxiv.org/abs/1912.10389) Lessons from Archives: Strategies for Collecting Sociocultural Data in Machine Learning<br>[Hutchinson et al., 2021](https://dl.acm.org/doi/10.1145/3442188.3445918) Towards Accountability for Machine Learning Datasets: Practices from Software Engineering and Infrastructure |
